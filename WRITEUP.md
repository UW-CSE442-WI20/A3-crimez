# CSE 442: A3-Crimez
###### Lior Levy, Amir Mola, Emma Raible, Heather Harvey, Kushal Jhunjhunwallla
 
Through our interactive visualization, we want to show our users historic crime data from 2009-2018 to determine which boroughs in NYC are safest for a person to live in. We show this by asking the question of **how has the distribution of NYC crime changed over the last 10 years**. This was a high level question, so we chose to break it down into the following sub questions:
- How do the boroughs compare in terms of all crime count for a given year? 
  - In which main premise types did crimes happen?
- How do the boroughs compare in terms of the count of a subset of all crime types in a given year?
  - In which main premise types did crimes happen?
  
For our final interactive visualization, we use a map and a bar graph which can both be filtered by year and crime type. The map is broken down into the 5 boroughs of NYC. As the year and crime filters change affect the colors of the colors of the boroughs change in accordance. The map addresses our main guiding questions, while the sub questions are answered in the bar graph that demonstrates the counts for the top 5 premise types where crimes occurred. Both the graph and map are affected by the filters simultaneously. 

One of our visual encodings was color saturation. The map is colored with a gradient, each color representing the amount of crime (light to dark correlates to least to most crime). Prior to making this decision, we did consider marking the exact locations of crimes with a dot at the provided latitudes and longitudes. However, we decided against this approach because we had millions of data points to plot which were all clustered and hard for a viewer to understand. Our main goal was to show the total amount of crimes that happened in each borough and we found that showing that through color intensity was better than the number of dots. A second visual encodings is the color decision. We chose to use a purple gradient for the map as that one was the best of all the other options we considered in d3.js color scale. With this color in mind, we chose to use a teal color for the bar graph. We did not want to keep a purple color for it so that there is no confusion that the two graphs are directly related. We chose teal as a pure design choice, since it is opposite of purple on the color wheel. Based on our research of color blindness, purple and teal should be able to be differentiated. But, even if a colorblind viewer could not detect a difference, these colors are not being used to show contrast between different fields. A viewer should still be able to see the gradient of the purple, while the bars and checkboxes that are colored teal will still have contrast from the black text. Therefore, even if a viewer could not differentiate between these two tones they should still be able to understand our visualization effectively. A third visual encoding decision was the size of the graphs. The map takes up most of our visualization while the bar graph is smaller and placed in the bottom left, below the filters. Our reasoning for this is that the map is our main focus in our guiding questions while the bar graph answers a sub question of those sub questions. In other words, the bar graph holds supporting information to our main information which the map holds, so it is emphasized less. 

For our interaction techniques, we decided to create a user friendly filtering feature that allows users to filter data based on the years and type of crime. Our data consists of 21 different types of crime that are represented by check boxes which users can select. We originally considered a drop-down as our main approach in filtering crime data, so that users could view all crimes at once or just one crime. However, we believe that the checkbox option is a better approach because it allows the users to choose multiple crimes at the same time. We also decided to choose a slider for time because it helps the viewer visualize the changes in the data as the years progress. There are additional interactions when the user hovers over the map or on the bars of the graph. While the color gradient on the map and the height of the bars confer the relation between factors, the hovering allows the user to see the exact number of crimes. When hovering, the opacity decreases on the non-selected elements and the selected element is outlined in black. This draws the users attention to the selected element, and prevents adding additional color tones which might be confusing, especially on the map. We encountered some problems when implementing the tooltip in that sometimes when the user moved the mouse away the crime stat box remained. From what we were able to find online, this is a common issue and there is no apparent fix on how to change this on our end. The issue tends to occur when moving the cursor very quickly, so perhaps the size in our data handling was causing the function to glitch.  

Our development process took quite some time, with an average of 6 hours a day per person over the course of a week and a half. We started the process with finding a good data set (which we had to clean up) as well as coming up with the questions we want to ask about it and deciding which interactive visualization(s) best answer them. Next, we continued with catching everyone up on how html, CSS, and JavaScript works and only then we all started learning d3.js. This part of our process took us the longest time (about 2 days). We attempted to learn how d3.js worked by looking at implemented examples of d3.js maps. Once we were able to implement a basic USA map is when we started to divide tasks (up to this point we were all working together) for phase 1 of our process. We made a to-do list on our README that stated all of the things we wanted to accomplish for this assignment and each person put their names next to what they wanted to work on. Because we are 5 people, there was a lot of pair programming. A basic version of the NYC map, the bar graphs, and the filters were developed independently and once those components were developed we regathered as a group to integrate it all together. We then entered phase 2 where we added more advanced functionalities to our visualization such as the mouseover (focus, tooltip), the different transitions, and more advanced filtration (such that both time and crime type affected the map and the bar graph). This phase took a while as well, about a week, and the one thing that took us the longest was the filter as we had to make a 3D dictionary for it. Once we got all of that down, we advanced to phase 3 which was the styling and formatting of everything which we did together. 

Over the course of our process, we changed our data 3 times - we started out with a small subset, then continued to what we thought was the whole data. Later we discovered that it was not the full data and had to change our data set once more. In all cases, we had to deal with data cleaning. Because we had kept a good guideline on that, it did not take too long to do the data cleaning 3 times (although, it could have been prevented). Some information about our data cleaning process. 

- We only looked at crimes in the years 2009 - 2018
- We faced a crime type that was recorded as 2 different strings, but we believe they represent the same crime and did not require different classifications. Thus, we changed “Intoxicated/impaired driving” to “Intoxicated & impaired driving”
- We excluded data with unknown premise types or unknown borough
- We also filtered down to the 6 columns we needed and chose the top 21 crime types.

The last iteration also resulted in extremely large files that took an hour to run a script to clean and were too large for JavaScript to handle without some workarounds.

Throughout all of this, we have discovered that Staten Island consistently has the lowest crime. Brooklyn, followed by Manhattan, has the highest crime. For the types of crime distribution, there’s a lot of variation, so we’ll leave that for you to explore.
